#+title: Kernel Collocation Excercise
#+author: Jonathan Ulmer (3545737)
#+bibliography: ~/org/roam/papers/bibliography.bib
#+latex_compiler: xelatex
#+latex_header: \newcommand{\RR}{\mathbb{R}}
#+latex_header: \usepackage{amsmath}
#+latex_header: \usepackage{amssymb}
#+latex_header: \newtheorem{remark}{Remark}
#+latex_header:\usepackage[T1]{fontenc}
#+latex_header: \usepackage{unicode-math}
#+latex_header: \setmonofont{DejaVu Sans Mono}[Scale=0.8]
#+Property: header-args:julia :eval never-export :async t :session *julia* :exports both :tangle src/snippets.jl :comments org
#+begin_export html
<div style="display:none">
\(
\newcommand{\RR}{\mathbb{R}}
\usepackage{amsmath}
\usepackage{amssymb}
\newtheorem{remark}{Remark}
\)
</div>
#+end_export
* Preamble :noexport:
#+begin_src julia :tangle src/kernel.jl :eval never

module Kernel
using StaticArrays
using KernelAbstractions
using LinearAlgebra
#+end_src
#+begin_src julia :tangle src/domains.jl :eval never
module Domains
using StaticArrays
using LinearAlgebra
export SquareDomain , LDomain , sdf_square , ∇sdf_square , unit_box_normals , unit_box_path , sdf_L , ∇sdf_L , sdf_L_grad , sdf_square_grad
#+end_src
#+begin_src julia :tangle src/pdesolver.jl :eval never
module PDESolvers
using SparseArrays
using IterativeSolvers

export PDESolver, PDESystem, solve
include("kernel.jl")

using .Kernel
using KernelAbstractions
using LinearAlgebra
#+end_src
* Distance Matrix Comutation :noexport:
#+begin_src julia

using KernelAbstractions
using StaticArrays
using Distributed
@kernel function distance_matrix!(A ,@Const(X_1) , @Const(X_2))
    # boilerplate
    Iᵢⱼ = @index(Global , Cartesian)
    @inbounds xᵢ= SVector{3}(view(X_1 , : , Iᵢⱼ[1]))
    @inbounds xⱼ= SVector{3}(view(X_2 , : , Iᵢⱼ[2]))
    # element computation
    @inbounds d = xᵢ - xⱼ
    @inbounds A[Iᵢⱼ] = d' * d
    end



function distM(X₁ ,X₂)
    A = KernelAbstractions.zeros(get_backend(X_1) , Float32 , size(X₁,2) , size(X₂,2))
    dist_kernel! = distance_matrix!(get_backend(A) , 256 , size(A))
    dist_kernel!(A ,X₁ , X₂ )
    KernelAbstractions.synchronize(get_backend(A))
    return A
end

function distK(X_1 , X_2)
norm_1 = sum(X_1.^2 ; dims=1)
norm_2 = sum(X_2.^2 ; dims=1)
distM = -2*(X_1'*X_2) .+ norm_1' .+ norm_2
end
#+end_src

#+begin_src julia :exports code :results none
using CUDA
using OpenCL
dev = CUDA.functional() ? cu : Array
#dev = CLArray
X_1 = rand(3,10_00) |> dev
X_2 = rand(3,10_00) |> dev

#+end_src


#+begin_src julia
using BenchmarkTools
@benchmark distK(X_1 , X_2)
#+end_src

#+RESULTS:
#+begin_example
BenchmarkTools.Trial: 5 samples with 1 evaluation per sample.
 Range (min … max):  939.480 ms …    1.252 s  ┊ GC (min … max):  0.36% … 25.33%
 Time  (median):        1.205 s               ┊ GC (median):    22.04%
 Time  (mean ± σ):      1.124 s ± 146.145 ms  ┊ GC (mean ± σ):  16.61% ± 11.64%

  █         █                                        █    █   █
  █▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁█▁▁▁█ ▁
  939 ms           Histogram: frequency by time          1.25 s <

 Memory estimate: 2.24 GiB, allocs estimate: 21.
#+end_example

#+begin_src julia
@benchmark distM(X_1, X_2)
#+end_src

#+RESULTS:
#+begin_example
BenchmarkTools.Trial: 2906 samples with 1 evaluation per sample.
 Range (min … max):  1.444 ms …   4.001 ms  ┊ GC (min … max): 0.00% … 31.03%
 Time  (median):     1.581 ms               ┊ GC (median):    0.00%
 Time  (mean ± σ):   1.717 ms ± 337.199 μs  ┊ GC (mean ± σ):  6.26% ± 11.19%

  ▂▇██▇▆▆▆▅▄▅▅▃▂             ▁▃▃▂▁    ▁▂▂▁                    ▂
  ███████████████▇█▇▅▅▇▄▅▆▅▆▇███████▆███████▇▇▇▇▇▅▇▄▅▁▄▅▁▁▇▇▇ █
  1.44 ms      Histogram: log(frequency) by time      2.95 ms <

 Memory estimate: 3.86 MiB, allocs estimate: 1011.
#+end_example

#+begin_src julia
using KernelAbstractions
@kernel function sparse_kernel(K)
Ind = @index(Global , Cartesian)
if abs(Ind[1] - Ind[2]) < 5
    K[Ind] = 1.
end
end
#+end_src

#+RESULTS:

#+begin_src julia
K = spzeros(10000,1000)
spkernel = sparse_kernel(CPU() , 256 , size(K))
spkernel(K)
#+end_src

#+RESULTS:
: julia-async:3c966bb3-f2f0-409e-a6f3-af3aca9bdfbd

* Regression Approach
Aim of this excrcise is to find solutions \(u\in \mathcal{H}_k\) such that they satisfy the following system

\begin{align}
\label{eq:pde}
- \nabla \cdot   \left( a(x) \nabla u(x) \right) &= f(x) & \text{in} \quad \Omega \\
u(x) &= g_D(x) & \text{on} \quad  \Gamma_D \\
\left( a(x) \nabla u(x)  \right) \cdot  \vec{n}(x) &= g_N & \text{on} \quad \Gamma_N
\end{align}
we do this by projecting the system onto \(\mathcal{H}_k(\Omega)\)
\begin{align}
\label{eq:pde_proj}
\left<   - \nabla \cdot   \left( a(x) \nabla u(x) \right),\phi \right>&= \left< f(x) ,\phi  \right> & \text{in} \quad \Omega , \phi \in  \mathcal{H}_{k} \\
\left<   u(x) , \phi \right>&= \left< g_D(x) , \phi  \right> & \text{on} \quad  \Gamma_D \\
\left<   \left( a(x) \nabla u(x)  \right) \cdot  \vec{n}(x) , \phi \right>&= \left< g_N ,\phi  \right> & \text{on} \quad \Gamma_N
\end{align}
Let \( \hat{X}:=\left\{ x_j \right\}_{j=1}^n \subset\RR ^d\). Since \(\left\{ k(x_i,\cdot ) \right\}_{i=1}^n\) is a basis of \(\mathcal{H}_k\) it also has to hold
\begin{align}
\label{eq:pde_proj}
\left<   - \nabla \cdot   \left( a(x) \nabla u(x) \right),k(x_i,\cdot ) \right>&= \left< f(x) ,k(x_i,\cdot )  \right> & \text{in} \quad \Omega , x_i \in  X \\
\left<   u(x) , k(x_i,\cdot ) \right>&= \left< g_D(x) , k(x_i,\cdot )  \right> & \text{on} \quad  \Gamma_D \\
\left<   \left( a(x) \nabla u(x)  \right) \cdot  \vec{n}(x) , k(x_i,\cdot ) \right>&= \left< g_N , k(x_i , \cdot )  \right> & \text{on} \quad \Gamma_N
\end{align}
We assuming \(f,g_D , g_N(\cdot ,\vec{n}) \in  \mathcal{H}_k\) i.e. \(\left< f , k(x_i , \cdot ) \right> = f(x_i)\) etc. We search for a finite approximation \(u_h \approx u\)
 such that it satisfies \eqref{eq:pde_proj} where
\begin{align}
\label{eq:approx}
u_h(x) &= \sum_{j=1}^{n} a_j k(x_j,x)
\end{align}
correspondingly we are able to directly compute

\begin{align*}
\nabla_x u_h(x) &= \sum_{j=1}^n a_j \nabla_x  k(x_j ,x) \\
- \nabla_x \cdot \left( a(x) \nabla_x u_h(x) \right) &= -  \nabla_x a(x) \cdot  \nabla_x u(x)  - a(x) \Delta_x u(x) \\
&=  - \sum_{j=1}^{n} a_j \left(  \nabla_x a(x) \cdot  \nabla_x k(x_j,x)   + a(x) \Delta_x k(x_j,x)\right)
\end{align*}
this leads to the following Linear system
\begin{align}
\label{eq:pde-sys}
 - \sum_{j=1}^{n} a_j \left(  \nabla_{x_i} a(x_i) \cdot  \nabla_{x_i} k(x_j,x_i)   + a(x_i) \Delta_{x_i} k(x_j,x_i)\right)&=  f(x_i)  & x_i\in  \Omega , x_i \in  X \\
 \sum_{j=1}^{n} a_j k(x_j,x_i)&=  g_D(x_i) & x_i\in   \Gamma_D \\
\sum_{j=1}^n  a_j \left( a(x_i) \nabla_{x_i}  k(x_j ,x_i) \cdot  n_i \right) &=  g_N(x_i , n_i) & x_i \in  \Gamma_N
\end{align}

this corresponds directly with the System Matrix \(K\), that we compute in julia using a GPU copatible kernel that employs element wise notation
#+begin_src julia :tangle src/kernel.jl

@kernel function system_matrix!(K ,@Const(X), a , ∇a ,k, ∇k, Δk  , sdf , grad_sdf , sdf_beta)
    Iᵢⱼ =  @index(Global , Cartesian)
    @inbounds xᵢ= SVector{2}(view(X, : , Iᵢⱼ[1])) # Essentially X[:,i]
    @inbounds xⱼ= SVector{2}(view(X, : , Iᵢⱼ[2])) # Essentially X[:,j]
    # poisson equation
    @inbounds K[Iᵢⱼ] = -a(xᵢ)*Δk(xᵢ,xⱼ)- ∇a(xᵢ)⋅∇k(xᵢ,xⱼ)
    if abs(sdf(xᵢ)) < 1e-10
        if sdf_beta(xᵢ) < 0
            # Neumann Boundary Condition
            @inbounds nᵢ= grad_sdf(xᵢ)
            @inbounds K[Iᵢⱼ] = a(xᵢ) * (nᵢ ⋅ ∇k(xᵢ , xⱼ))
        else
          # Dirichlet Boundary
          @inbounds K[Iᵢⱼ] =k(xᵢ , xⱼ)
        end
    end
end
#+end_src

** right hand side
The right hand side of the system is computed in a similar Fashion
#+begin_src julia :tangle src/kernel.jl

@kernel function apply_function_colwise!(B ,@Const(X) , f , g_D , g_N , sdf  , grad_sdf, sdf_beta)
    # boilerplate
    Iᵢ = @index(Global , Cartesian)
    @inbounds xᵢ= SVector{2}(view(X , : , Iᵢ[1]))
    # poisson equation

    @inbounds B[Iᵢ] = f(xᵢ)
    if abs(sdf(xᵢ)) < 1e-10
         if sdf_beta(xᵢ) < 0
             # Neumann Boundary Condition
             @inbounds nᵢ= grad_sdf(xᵢ)
             @inbounds B[Iᵢ] = g_N(xᵢ , nᵢ )
         else
            # Dirichlet Boundary
            @inbounds B[Iᵢ] = g_D(xᵢ)
         end
     end
end
#+end_src

* Solver

#+RESULTS:

#+begin_src julia :tangle src/pdesolver.jl :eval never
struct PDESystem
    k :: Function
    ∇k :: Function
    Δk :: Function
    a :: Function
    ∇a::Function
    f::Function
    g_D::Function
    g_N::Function
    sdf::Function
    grad_sdf::Function
    sdf_beta::Function
end

struct PDESolver
    S::PDESystem
    X::AbstractMatrix
    α :: AbstractVector
end

function (f::PDESolver)(X)
    dev = get_backend(X)
    print("Backend" , dev)
    K = KernelAbstractions.zeros(dev , Float32, size(X,2)  , size(f.X ,2))
    print("Size of the system Matrix:" , size(K))
    kernel_matrix! = dirichlet_matrix!( dev , 256 , size(K))
    kernel_matrix!(K, X , f.X , f.S.k )
return K * f.α , K
end

function solve(S, X_col)
    dev = get_backend(X_col)
    K = KernelAbstractions.zeros(dev , Float32 , size(X_col , 2) , size(X_col , 2) )
    sys_matrix! = system_matrix!( dev , 256 , size(K))
    sys_matrix!(K ,X_col , S.a , S.∇a , S.k , S.∇k , S.Δk , S.sdf , S.grad_sdf , S.sdf_beta  )
    B = get_boundary(S,X_col)
    α = K \ B
    return (PDESolver(S,X_col ,α) , K)
    end


function get_boundary(
    S,
    X
    )
    dev = get_backend(X)
    B = KernelAbstractions.zeros(dev , Float32 , size(X , 2))
    apply! = apply_function_colwise!(dev , 256 , size(B))
    apply!(B , X , S.f , S.g_D , S.g_N , S.sdf  , S.grad_sdf, S.sdf_beta)
    return B
    end

#+end_src

#+begin_src julia :tangle src/pdesolver.jl
end
#+end_src

* Kernel Implementation
As kernels we use Radial Basis Kernels (RBF) \(k(x,x') := \phi (\frac{\|x-x'\|}{\gamma})\). That consist of a radial basis function \(\phi \) as well as a scaling factor \(\gamma \)
where \(\nabla_x , \Delta_x\) are the partial gradients and laplacians with respect to the second argument of \(k(x_j, \cdot )\).
for a radial basis function \(\phi (r^2) \in  C^2(\RR)\)  and a corresponding RBF kernel  they can be computed trivially
\begin{align}
\label{eq:2}
\nabla_x k(x',x) &= \phi'\left(\frac{\|x - x'\|}{\gamma}\right) \cdot \frac{x - x'}{\gamma\|x - x'\|} \\
\Delta_x k(x',x) &= \frac{1}{\gamma^2} \phi''\left(\frac{\|x - x'\|}{\gamma}\right) + \frac{1}{\gamma^{2}} \frac{d - 1}{\|x - x'\|} \cdot \phi'\left(\frac{\|x - x'\|}{\gamma}\right)
\end{align}
where \(d\) is the dimension of \(x\)
#+begin_src julia
using StaticArrays
@inline function k(ϕ::Function , ::Val{γ},x̂::SVector{N} ,x::SVector{N}) where {N , γ , RBFType}
    r = max(1e-15,norm(x-x̂)/γ)
    ϕ(r)
    end
@inline function ∇k(dϕ::Function , ::Val{γ} ,x̂::SVector{N} ,x::SVector{N}) where {N , γ , dRBFType}
    r = max(1e-15,norm(x-x̂)/γ)
    (x-x̂)*dϕ(r) *  1/(r*γ^2)
    end
@inline function Δk(d²ϕ::Function,  dϕ::Function , ::Val{γ} ,x̂::SVector{N} ,x::SVector{N}) where {N , γ , ddRBFType}
    r = max(1e-15,norm(x-x̂)/γ)
    1/γ^2 * d²ϕ(r)  +  1/γ^2 * (N-1)/r *dϕ(r)
    end
#+end_src

#+RESULTS:
: Δk (generic function with 1 method)
** squared rbf
for a squared RBF the kernels are simpler. and non singular
\begin{align}
\label{eq:sqr-rbf}
\nabla_x k(x',x) &= \phi'\left(\frac{r^2}{\gamma}\right) \cdot \frac{x - x'}{\gamma} \\
\Delta_x k(x',x) &= \frac{1}{\gamma } (4 * \frac{r^2}{\gamma^2} \phi''\left(\frac{r^2}{\gamma}\right) + 2d\phi'\left(\frac{r^2}{\gamma}\right))
\end{align}
#+begin_src julia
using StaticArrays
using LinearAlgebra
@inline function ksq(ϕ::RBFType , ::Val{γ},x̂::SVector{N} ,x::SVector{N}) where {N , γ , RBFType}
    r = dot(x-x̂,x-x̂)/γ^2
    ϕ(r)
    end
@inline function ∇ksq(dϕ::dRBFType , ::Val{γ} ,x̂::SVector{N} ,x::SVector{N}) where {N , γ , dRBFType}
    r = dot(x-x̂,x-x̂)/γ^2
    2/γ^2*(x-x̂)*dϕ(r)
    end
@inline function Δksq(d²ϕ::ddRBFType,  dϕ::Function , ::Val{γ} ,x̂::SVector{N} ,x::SVector{N}) where {N , γ , ddRBFType}
    r = dot(x-x̂,x-x̂)/γ^2
    1/γ^2 * (4*r * d²ϕ(r)  +  2*N*dϕ(r))
    end
#+end_src

#+RESULTS:
: Δksq (generic function with 1 method)

** Gauss
#+begin_src julia :tangle src/gauss_kernel.jl
using StaticArrays
@inline function rbf_gaussian(r)
    exp(-r)
    end
@inline function d_rbf_gaussian(r)
    -exp(-r)
    end
@inline function dd_rbf_gaussian(r)
    exp(-r)
    end
#+end_src

#+RESULTS:
: dd_rbf_gaussian (generic function with 1 method)

#+begin_src julia :results file graphics :file "images/gauss-rbf.png"
using GLMakie
X = range(-2 , 2 , 100)
Y = range(-5 , 5 , 100)
using LinearAlgebra

fig = Figure()
ax = Axis(fig[1,1])
lines!(X , x->rbf_gaussian(x^2))
save("images/gauss-rbf.png",fig )
#+end_src

#+RESULTS:
[[file:images/gauss-rbf.png]]

** Cardinal B_{3} Spline

\begin{align*}
B_{d}(r) = \sum_{n=0}^4 \frac{(-1)^n}{d!} \binom{d+1}{n} \left( r + \frac{d+1}{2}-n \right)^d_+
\end{align*}
#+begin_src julia
function B_3(r)
r_prime = r+2
    return 1/24 * (
    1 *max(0, (r_prime - 0))^3
    -4*max(0, (r_prime - 1))^3
    +6*max(0, (r_prime - 2))^3
    -4*max(0, (r_prime - 3))^3
    +1*max(0, (r_prime - 4))^3
    )
end
function d_B_3(r)
r_prime = r+2
    return 1/8 * (
    1 *max(0, (r_prime - 0))^2
    -4*max(0, (r_prime - 1))^2
    +6*max(0, (r_prime - 2))^2
    -4*max(0, (r_prime - 3))^2
    +1*max(0, (r_prime - 4))^2
    )
end
function dd_B_3(r)
r_prime = r+2
    return 1/4 * (
    1 *max(0, (r_prime - 0))
    -4*max(0, (r_prime - 1))
    +6*max(0, (r_prime - 2))
    -4*max(0, (r_prime - 3))
    +1*max(0, (r_prime - 4))
    )
end

#+end_src

#+RESULTS:

#+name: fig:b-spline
#+begin_src julia :results file graphics :file "images/b-spline.png"
using GLMakie
using LaTeXStrings
X = range(-2 , 2 , 100)
Y = range(-2 , 2 , 100)

fig = Figure()
ax = Axis(fig[1,1])

lines!(ax , X , B_3 , label=L"B_3")
lines!(ax , X , d_B_3 , label=L"\partial B_3")
lines!(ax , X , dd_B_3 , label=L"\partial^2 B_3")
axislegend(ax)
save("images/b-spline.png",fig )
#+end_src

#+RESULTS: fig:b-spline
[[file:images/b-spline.png]]

** Thin Plate
\begin{align*}
T(r^2) &= \frac{1}{2}r\ln{r} \\
T(r) &= r^2\ln{r}
\end{align*}
#+begin_src julia
function thin_plate(r)
    r == 0.0 && return 0.0
    return 0.5* r *  log(r)
end

function d_thin_plate(r)
    r == 0.0 && return 0.0
    return 0.5 * log(r) + 1
end

function dd_thin_plate(r)
    r == 0.0 && return 0.0
    return 0.5 * 1/r
end
#+end_src

#+RESULTS:
: dd_thin_plate (generic function with 1 method)

#+name: fig:plate-spline
#+begin_src julia :results file graphics :file "images/plate-spline.png"
using GLMakie
X = range(0 , 1 , 100)
Y = range(-5 , 5 , 100)

fig = Figure()
ax = Axis(fig[1,1])

lines!(ax , X , thin_plate)

save("images/plate-spline.png",fig )
#+end_src

#+RESULTS: fig:plate-spline
[[file:images/plate-spline.png]]

* PDE
#+begin_src julia
using Revise
using LinearAlgebra
includet("src/pdesolver.jl")
includet("src/domains.jl")
using .PDESolvers
using .Domains
#+end_src

#+RESULTS:

** PDE Poisson
with \(a(x) = 1 , g_{D}(x) = 0\) and \(\Gamma_{N} = \emptyset \) this method is able to model the poisson equation
\begin{align}
\label{eq:poisson}
- \Delta u(x) &= f(x) & \text{in} \quad \Omega \\
u(x) &= 0 & \text{on} \quad  \Gamma_D
\end{align}
#+begin_src julia :results silent
using StaticArrays
function domain(x::SVector{2})
    return sdf_square(x , 0.5 , SVector(0.5,0.5))
end
function ∇domain(x::SVector{2})
    return sdf_square_grad(x , 0.5 , SVector(0.5,0.5))
end
function sdf_β(x::SVector{2})
    return sdf_square(x , 0. , SVector(-1.,-1) )
end

a(x::SVector{2}) = 1
∇a(x::SVector{2}) = SVector{2}(0.,0.)
f(x::SVector{2}) =2 * (x[1]+x[2] - x[1]^2 - x[2]^2)
g_D(x::SVector{2})= 0
g_N(x::SVector{2} , n::SVector{2}) = 0
#+end_src

#+begin_src julia
using CUDA
dev = CUDA.functional() ? cu : Array
#dev = Array
X = range(0 , 1 , 20)
Y = range(0 , 1 , 20)
X_col = [ [x,y] for x in X , y in Y]
X_col = reduce(vcat ,X_col )
X_col = reshape(X_col, 2,:) |> dev
X_t = range(0 , 1 , 100)
Y_t = range(0 , 1 , 100)
X_test = [ [x,y] for x in X_t , y in Y_t]
X_test = reduce(vcat , X_test)
X_test = reshape(X_test, 2,:) |> dev
X_lol = rand(2,400) |> dev


size(X_col)
#+end_src

#+RESULTS:
: (2 400)
*** Result



#+begin_src julia :results silent
γ = 0.01
@inline k_gauss(x,y) = @inline ksq( rbf_gaussian ,Val(0.1), x,y)
@inline ∇k_gauss(x,y) =@inline ∇ksq(d_rbf_gaussian,Val(0.1) , x,y)
@inline Δk_gauss(x,y) =@inline Δksq(dd_rbf_gaussian , d_rbf_gaussian ,Val(0.1), x,y)
S_gauss = PDESystem(k_gauss , ∇k_gauss , Δk_gauss , a, ∇a , f, g_D ,g_N , domain , ∇domain , sdf_β )
#+end_src

#+begin_src julia :results silent
k_plate(x,y) = ksq(thin_plate ,γ , x,y)
∇k_plate(x,y) =∇ksq(d_thin_plate ,γ , x,y)
Δk_plate(x,y) = Δksq(dd_thin_plate  , d_thin_plate ,γ, x,y)
S_plate = PDESystem(k_plate , ∇k_plate , Δk_plate , a, ∇a , f, g_D ,g_N , domain , ∇domain , sdf_β )
#+end_src


#+begin_src julia :results silent
γ = 0.01
k_bspline(x,y) = k(B_3,γ , x,y)
∇k_bspline(x,y) =∇k(d_B_3,γ , x,y)
Δk_bspline(x,y) = Δk(dd_B_3, d_B_3, γ , x,y)
S_bspline = PDESystem(k_bspline , ∇k_bspline , Δk_bspline , a, ∇a , f, g_D ,g_N , domain , ∇domain , sdf_β )
#+end_src



#+begin_src julia
using LinearAlgebra
solution , K = solve(S_gauss ,X_lol);
#cond(K)

#+end_src

#+RESULTS:



#+name: fig:solution
#+begin_src julia :results file graphics :file "images/solution.png"
using GLMakie
fig = Figure()
ax = Axis(fig[1,1] , title="Aproximate solution", aspect=DataAspect())
sol , K_t = solution(X_test)
sol = reshape(Array(sol) , size(X_t,1) , :)
hm = heatmap!(ax , X,Y, sol)
Colorbar(fig[:, end+1], hm)
save("images/solution.png",fig )
#+end_src

#+RESULTS: fig:solution
[[file:images/solution.png]]

#+name: fig:exact-solution
#+begin_src julia :results file graphics :file "images/exact-solution.png"
using GLMakie
u(x , y) = x * (1-x) * y* ( 1- y)
u(x) = u(x[1] , x[2])
fig = Figure()
ax = Axis(fig[1,1] , title="Exact sollution" , aspect=DataAspect())

hm = heatmap!(ax,X_t,Y_t,u)
Colorbar(fig[:, end+1], hm)
save("images/exact-solution.png",fig )
#+end_src

#+RESULTS: fig:exact-solution
[[file:images/exact-solution.png]]

#+begin_src julia
sol , _ = solution(X_test)
norm(Array(sol) - u.(eachcol(Array(X_test))) , Inf)
#+end_src

#+RESULTS:
: 0.00085476646f0

** Diffusion PDE

*** Result
where
#+begin_src julia
using StaticArrays
a(x::SVector{2}) = x[1] + 2
∇a(x::SVector{2}) = SVector{2}(1.,0.)
α = 2.
β = 1.5
f(x::SVector{2} , ::Val{α}) where α = - α*norm(x ,2)^(α - 2)*(3x[1] +4) - α*(α -2) * (x[1] + 2) * norm(x,2)^(α - 3)
g_D(x::SVector{2} , ::Val{α}) where α = norm(x,2)^α
g_N(x::SVector{2} , n::SVector{2} , ::Val{α}) where α = α* norm(x,2.)^(α-2.)*(x[1] +2.) * x ⋅ n
f(x) = f(x,Val(α))
g_D(x) = g_D(x,Val(α))
g_N(x, n) = g_N(x , n,Val(α))
function sdf_β(x::SVector{2})
    return sdf_square(x , β , SVector(-1.,-1) )
end
S = PDESystem(k_gauss , ∇k_gauss , Δk_gauss , a, ∇a , f, g_D ,g_N , sdf_L , sdf_L_grad , sdf_β )
#+end_src

#+RESULTS:
: PDESystem(Main.k_gauss, Main.∇k_gauss, Main.Δk_gauss, Main.a, Main.∇a, Main.f, Main.g_D, Main.g_N, Main.Domains.sdf_L, Main.Domains.sdf_L_grad, Main.Domains.sdf_β)

#+begin_src julia
X = range(-1 , 1 , 30)
Y = range(-1 , 1 , 30)
X_col = [ [x,y] for x in X , y in Y]
X_col = reduce(vcat ,X_col )
X_col = reshape(X_col, 2,:)
X_t = range(-2 , 2 , 100)
Y_t = range(-2, 2 , 100)
X_test = [ [x,y] for x in X_t , y in Y_t]
X_test = reduce(vcat , X_test)
X_test = reshape(X_test, 2,:)
size(X_col)
#+end_src

#+RESULTS:
: (2 900)

#+begin_src julia
using LinearAlgebra
solution , K = solve(S ,X_col)
cond(K)
#+end_src

#+RESULTS:
: 221981.19f0

#+name: fig:diffusion-solution
#+begin_src julia :results file graphics :file "images/diffusion-solution.png"
using GLMakie
fig = Figure()
ax = Axis(fig[1,1] , title="Aproximate solution")
sol , K = solution(X_test)
sol = reshape(sol , size(X_t,1) , :)
hm = heatmap!(ax , X,Y, sol)
Colorbar(fig[:, end+1], hm)
save("images/diffusion-solution.png",fig )
#+end_src

* Domains
#+begin_src julia :tangle src/domains.jl :eval never

function sdf_square(x::SVector , r::Float64 , center::SVector)
    return norm(x-center,Inf) .- r
end
function sdf_L(x::SVector{2})
    return max(sdf_square(x , 1. , SVector(0,0)) , - sdf_square(x, 1. , SVector(1.,1.)))
end

function ∇sdf_L(x::SVector{2})
    ForwardDiff.gradient(sdf_L , x)
    return
end

function sdf_square_grad(x::SVector{2}, r::Float64, center::SVector{2})
    d = x - center
    if abs(d[1]) > abs(d[2])
        return SVector(sign(d[1]), 0.0)
    elseif abs(d[2]) > abs(d[1])
        return SVector(0.0, sign(d[2]))
    else
        # Subgradient: pick any valid direction; here we average the two
        return normalize(SVector(sign(d[1]), sign(d[2])))
    end
end

function sdf_L_grad(x::SVector{2})
    f1 = sdf_square(x, 1.0, SVector(0.0, 0.0))
    f2 = -sdf_square(x, 1.0, SVector(1.0, 1.0))

    if f1 > f2
        return sdf_square_grad(x, 1.0, SVector(0.0, 0.0))
    elseif f2 > f1
        return -sdf_square_grad(x, 1.0, SVector(1.0, 1.0))  # negative because of the minus
    else
        # Subgradient — average of both directions
        g1 = sdf_square_grad(x, 1.0, SVector(0.0, 0.0))
        g2 = -sdf_square_grad(x, 1.0, SVector(1.0, 1.0))
        return normalize(g1 + g2)
    end
end
#+end_src


* Appendix :noexport:
** Linear Sytem
#+begin_src julia :tangle src/kernel.jl

@kernel function linear_matrix!(A ,@Const(X_L) , @Const(X) , k, ∇k , Δk , a , ∇a)
    # boilerplate
    Iᵢⱼ = @index(Global , Cartesian)
    @inbounds xᵢ= SVector{2}(view(X_L , : , Iᵢⱼ[1]))
    @inbounds xⱼ= SVector{2}(view(X , : , Iᵢⱼ[2]))
    # element computation
    @inbounds A[Iᵢⱼ] = ∇a(xᵢ)⋅∇k(xᵢ,xⱼ) -  a(xᵢ)Δk(xⱼ,xᵢ)
    end
#+end_src

#+RESULTS:
: linear_matrix! (generic function with 4 methods)

** Dirichlet boundary
The Dirichlet boundary confitions are dealt with as additional condition in the linear system
#+begin_src julia :tangle src/kernel.jl

@kernel function dirichlet_matrix!(A , @Const(X_D) , @Const(X) ,k)
    Iᵢⱼ =  @index(Global , Cartesian)
    @inbounds xᵢ= SVector{2}(view(X_D , : , Iᵢⱼ[1])) # Essentially X[:,1]
    @inbounds xⱼ= SVector{2}(view(X , : , Iᵢⱼ[2]))
    K = k(xᵢ , xⱼ)
    @inbounds A[Iᵢⱼ] = K
end
#+end_src

#+RESULTS:
: julia-async:f35f44a7-4d8a-4825-9dd8-78915cf364bd
** Neumann Boundary

#+begin_src julia :tangle src/kernel.jl

@kernel function neumann_matrix!(A , @Const(X_N) , @Const(X) , @Const(N) , a , ∇k )
    Iᵢⱼ =  @index(Global , Cartesian)
    @inbounds xᵢ= SVector{2}(view(X_N , : , Iᵢⱼ[1])) # Essentially X[:,1]
    @inbounds xⱼ= SVector{2}(view(X , : , Iᵢⱼ[2]))
    @inbounds nᵢ= SVector{2}(view(N , : , Iᵢⱼ[1]))
    @inbounds A[Iᵢⱼ] = a(xᵢ) * (nᵢ ⋅ ∇k(xᵢ , xⱼ))
    end
#+end_src

#+RESULTS:
** alternative approach
#+begin_src julia :tangle nil
function assemble_kernel_matrix(
    S,
    X_L :: AbstractMatrix ,
    X_D :: AbstractMatrix ,
    X_N :: AbstractMatrix ,
    N :: AbstractMatrix
)
    local X = [X_L X_D X_N]
    DOF = size(X,2)
    dev = get_backend(X)
    print("Backend" , dev)
    K = KernelAbstractions.zeros(dev , Float32,DOF ,DOF)
    print("Size of the system Matrix:" , size(K))
    K_linear = @view K[begin:size(X_L , 2) , :]
    K_dirichlet = @view K[size(X_L , 2)+1:end - size(X_N ,2), :]
    K_neumann = @view K[end-size(X_N ,2)+1:end, :]


    cpu_linear! = linear_matrix!( dev , 64 , size(K_linear))
    cpu_dirichlet! = dirichlet_matrix!( dev , 64 , size(K_dirichlet))
    cpu_neumann! = neumann_matrix!( dev , 64 , size(K_neumann))

    cpu_linear!(K_linear  , X_L , X , S.k , S.∇k , S.Δk , S.a , S.∇a)
    @info "Linear"
    cpu_dirichlet!(K_dirichlet  , X_D , X , S.k )
    @info "Dirichlet"
    cpu_neumann!(K_neumann  , X_N , X , N ,S.a, S.∇k)
    @info "Neumann"
    KernelAbstractions.synchronize(dev)
    return K
end
function solve(
    S,
    X_L :: AbstractMatrix ,
    X_D :: AbstractMatrix ,
    X_N :: AbstractMatrix ,
    N :: AbstractMatrix
    )
    K = assemble_kernel_matrix(S, X_L , X_D , X_N , N)
    b = get_boundary(S,X_L , X_D , X_N , N)
    @info "calulating pinv"
    α =  b'*pinv(K)
    @info "calculated pinv"
    return PDESolver(S, X_L , X_D , X_N , N , α' )
    #return b, K

    end
#+end_src

#+begin_src julia :results silent
using Random
using CUDA
dev = CUDA.functional() ? cu : Array
rng = MersenneTwister(0)
r = 0:0.2:1.99
N = unit_box_normals.(r)
N = reduce(hcat , N) |> dev
X_N = unit_box_path.(r)
X_N = reduce(hcat , X_N)|> dev
X_D = unit_box_path.(2:0.1:4)
X_D = reduce(hcat , X_D) |> dev
X_L = rand(rng , Float64, 2,100) |> dev

#+end_src


#+name: fig:collocation-points
#+begin_src julia :results file graphics :file "images/collocation-points.png"
using LaTeXStrings
using Makie
using GLMakie
fig = Figure()
ax = Axis(fig[1,1] , title="Collocation Points")

scatter!(ax,X_L |> Array, label="Data Points")
scatter!(ax,X_D|> Array, label="Dirichlet Points")
scatter!(ax,X_N |> Array, label="Neumann Points")
arrows!(ax,X_N[1,:]|> Array , X_N[2,:] |> Array, N[1,:] |> Array, N[2,:] |> Array, lengthscale=0.1)
axislegend(ax , position=:lt)
save("images/collocation-points.png",fig )
#+end_src
** Postamble
#+begin_src julia :tangle src/kernel.jl :eval never

export linear_matrix!
export dirichlet_matrix!
export neumann_matrix!
export apply_function_colwise!
export system_matrix!
end
#+end_src

#+begin_src julia :tangle src/domains.jl :eval never
function unit_box_normals(γ::Float64)
    p = SVector{2}(0,0)
    xnormal = SVector{2}(1,0)
    ynormal = SVector{2}(0,1)
    branch = γ % 4.
    if floor(branch) == 0.
        n = -ynormal
    elseif floor(branch) == 1.
        n = xnormal
    elseif floor(branch) == 2.
        n = ynormal
    elseif floor(branch) == 3.
        n = -xnormal
    else
        throw("γ=$γ not in range [0 , 4]")
    end

    return n
end
function unit_box_path(γ::Float64)
    p = SVector{2}(0,0)
    xnormal = SVector{2}(1,0)
    ynormal = SVector{2}(0,1)
    branch = γ % 4.
    if floor(branch) == 0.
        p = branch%1 * xnormal
    elseif floor(branch) == 1.
        p = xnormal +  branch%1 * ynormal
    elseif floor(branch) == 2.
        p = (1-branch%1)*xnormal + ynormal
    elseif floor(branch) == 3.
        p = (1-branch%1) * ynormal
    else
        throw("γ=$γ not in range [0 , 4]")
    end
    return p
end
#+end_src

** Postable

#+begin_src julia :tangle src/domains.jl :eval never
end
#+end_src
